# Argus V2 â€” System Architecture Design Document

> Implementation based on the methodology from the paper *"Argus AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives"* (arXiv:2509.08380v2).

---

## 1. Architecture Overview

### 1.1 Design Principles

| Principle | Description |
|---|---|
| **Agentic Decomposition** | Decompose SAR generation into multiple specialized Agents, each with a single responsibility and independently evolvable |
| **LangGraph-Driven** | All Agent orchestration is based on LangGraph state graphs, enabling controllable and observable workflows |
| **Human-in-the-Loop** | Human investigators are always in the loop; AI generates drafts for review, never auto-submits |
| **Privacy-First** | Sensitive data must be anonymized by the AI-Privacy Guard before being sent to any LLM |
| **Monolithic Deployment** | Single-process Streamlit application with internal LangGraph orchestration, reducing operational complexity |

### 1.2 Technology Stack

| Layer | Choice | Rationale |
|---|---|---|
| **Language** | Python 3.11+ | Most mature ecosystem for Agent / LLM / NLP development |
| **Agent Orchestration** | LangGraph (v0.2+) | Provides stateful graph execution, conditional routing, human-in-the-loop interrupts, and checkpoint persistence |
| **LLM** | DeepSeek (Primary) | Primary support; extensible to other models via a unified Gateway |
| **LLM Integration** | LangChain ChatModel Abstraction | Native LangGraph support, unified interface for DeepSeek / OpenAI / Anthropic |
| **Privacy Layer** | RoBERTa + CRF (Paper Design) | MVP stage uses presidio / spaCy NER first, later replaced with self-trained model |
| **Crime Type Detection** | scikit-learn (RF / GBM) | Tree-based ensemble methods as specified in the paper |
| **Memory Layer** | ChromaDB (Vector) + SQLite (Structured) | Lightweight, suitable for monolithic deployment |
| **UI Framework** | Streamlit | Rapid data application UI development with native support for interactive widgets, real-time streaming, and Session State management |
| **Data Format** | JSON | Unified JSON for input / output / sample data |
| **Configuration** | Pydantic Settings + YAML | Type-safe configuration loading |

---

## 2. System Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Streamlit Application                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                   UI Layer (Streamlit)                     â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  ðŸ“„ Case Upload    â€” JSON file upload / sample selection   â”‚  â”‚
â”‚  â”‚  ðŸ” SAR Generate   â€” One-click trigger, real-time stream   â”‚  â”‚
â”‚  â”‚  âœï¸ Narrative Review â€” Draft display + inline edit + feedbackâ”‚ â”‚
â”‚  â”‚  ðŸ“Š Analysis Dashboard â€” Crime types, risk, compliance viz â”‚  â”‚
â”‚  â”‚  ðŸ“‹ History        â€” Historical SAR list + search + export â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  State Mgmt: st.session_state (case data/graph state/feedback)â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              LangGraph Orchestration Layer                 â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚           SARGenerationGraph (Main Graph)           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  [ingest] â†’ [privacy_mask] â†’ [crime_detect]         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚      â†’ [plan] â†’ [typology_subgraph] â”€â”€â”             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                       â–¼             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚      [external_intel] â†’ [narrative_generate]        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚           â†’ [compliance_validate] â”€â”€â”               â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                     â–¼               â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€ PASS â”€â”€â”€â”€ [privacy_unmask] â†’ [human_review]  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                                       â”‚          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚    FAIL â”€â”€ [feedback_refine] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                  â–²        â”‚                       â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ (iteration)           â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚      TypologySubgraph (Subgraph, Dynamic Parallel)  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚                                                     â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  [transaction_fraud]     [payment_velocity]         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  [country_risk]          [text_content]             â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  [geo_anomaly]           [account_health]           â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  [dispute_pattern]                                  â”‚  â”‚  â”‚
â”‚  â”‚  â”‚        â”€â”€â”€â”€ all converge â†’ [typology_merge] â”€â”€â”€â”€    â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                 Infrastructure Layer                      â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ Privacy    â”‚ â”‚ LLM        â”‚ â”‚ Dynamic Memory         â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Guard      â”‚ â”‚ Gateway    â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ (NER+CRF)  â”‚ â”‚ (DeepSeek) â”‚ â”‚ â”‚Reg.Mem â”‚ â”‚Hist.Memâ”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚ â”‚            â”‚ â”‚ â”‚(Chroma)â”‚ â”‚(Chroma)â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚ â”‚            â”‚ â”‚ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚ â”‚            â”‚ â”‚ â”‚Typo.Memâ”‚ â”‚State   â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â”‚            â”‚ â”‚            â”‚ â”‚ â”‚(SQLite)â”‚ â”‚(SQLite)â”‚  â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â”‚  â”‚
â”‚  â”‚                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚  â”‚ Data       â”‚ â”‚ Analytical â”‚ â”‚ MCP Client             â”‚ â”‚  â”‚
â”‚  â”‚  â”‚ Ingestion  â”‚ â”‚ Tools      â”‚ â”‚ (External Intel)       â”‚ â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. LangGraph Core Design

### 3.1 Global State (State Schema)

LangGraph uses a **TypedDict** to define the shared state that flows through the entire workflow. All Agents (nodes) read from and write to the same State object:

```python
class SARState(TypedDict):
    # â”€â”€ Input Data â”€â”€
    case_id: str                          # Unique case identifier
    raw_data: dict                        # Raw JSON case data
    structured_data: dict                 # Structured/normalized data
    masked_data: dict                     # Anonymized data
    mask_mapping: dict                    # Anonymization mapping table (for de-masking)

    # â”€â”€ Crime Type Detection â”€â”€
    risk_indicators: list[dict]           # Extracted risk indicators
    crime_types: list[CrimeTypeResult]    # Detected crime types + confidence scores

    # â”€â”€ Planning â”€â”€
    execution_plan: ExecutionPlan         # Execution plan generated by the Planning Agent
    active_typology_agents: list[str]     # List of typology agents to activate

    # â”€â”€ Typology Detection Results â”€â”€
    typology_results: dict[str, dict]     # Analysis results from each typology agent

    # â”€â”€ External Intelligence â”€â”€
    external_intel: list[dict]            # External intelligence retrieved via MCP

    # â”€â”€ Narrative Generation â”€â”€
    narrative_draft: str                  # Current narrative draft
    narrative_intro: str                  # Narrative introduction section
    chain_of_thought: list[str]           # Chain-of-Thought reasoning trace

    # â”€â”€ Compliance Validation â”€â”€
    compliance_result: ComplianceResult   # Validation result (PASS/FAIL + details)
    compliance_score: float               # Compliance score

    # â”€â”€ Human-in-the-Loop â”€â”€
    human_feedback: str | None            # Human feedback content
    iteration_count: int                  # Current iteration round
    max_iterations: int                   # Maximum iteration count

    # â”€â”€ Final Output â”€â”€
    final_narrative: str                  # Final SAR narrative
    status: Literal["processing", "review", "approved", "rejected"]
    messages: Annotated[list, add_messages]  # Inter-agent message log
```

### 3.2 Main Graph (SARGenerationGraph)

```python
from langgraph.graph import StateGraph, START, END

graph = StateGraph(SARState)

# â”€â”€ Register Nodes (each node corresponds to an Agent function) â”€â”€
graph.add_node("ingest",              data_ingestion_agent)
graph.add_node("privacy_mask",        privacy_mask_agent)
graph.add_node("crime_detect",        crime_detection_agent)
graph.add_node("plan",                planning_agent)
graph.add_node("typology_analysis",   typology_subgraph)      # Subgraph
graph.add_node("external_intel",      external_intel_agent)
graph.add_node("narrative_generate",  narrative_generation_agent)
graph.add_node("compliance_validate", compliance_validation_agent)
graph.add_node("privacy_unmask",      privacy_unmask_agent)
graph.add_node("feedback_refine",     feedback_agent)

# â”€â”€ Define Edges (linear + conditional routing) â”€â”€
graph.add_edge(START,                 "ingest")
graph.add_edge("ingest",             "privacy_mask")
graph.add_edge("privacy_mask",       "crime_detect")
graph.add_edge("crime_detect",       "plan")
graph.add_edge("plan",               "typology_analysis")
graph.add_edge("typology_analysis",  "external_intel")
graph.add_edge("external_intel",     "narrative_generate")
graph.add_edge("narrative_generate", "compliance_validate")

# Conditional routing: compliance pass â†’ unmask output; fail â†’ feedback iteration
graph.add_conditional_edges(
    "compliance_validate",
    compliance_router,          # Routing function
    {
        "pass": "privacy_unmask",
        "fail": "feedback_refine",
    }
)

graph.add_edge("privacy_unmask",     END)   # Output for human review

# Feedback iteration: return to narrative generation
graph.add_edge("feedback_refine",    "narrative_generate")

# â”€â”€ Compile (enable checkpoint persistence) â”€â”€
from langgraph.checkpoint.sqlite import SqliteSaver
checkpointer = SqliteSaver.from_conn_string("checkpoints.db")
app = graph.compile(
    checkpointer=checkpointer,
    interrupt_before=["privacy_unmask"],  # Human-in-the-loop interrupt point
)
```

### 3.3 Typology Detection Subgraph (TypologySubgraph)

Leverages LangGraph's **Send API** for dynamic parallelism: based on the Planning Agent's decisions, only the required Typology Agents are activated.

```python
from langgraph.constants import Send

def plan_to_typology_dispatch(state: SARState) -> list[Send]:
    """Dynamically dispatch to corresponding Typology Agents based on the execution plan"""
    sends = []
    for agent_name in state["active_typology_agents"]:
        sends.append(Send(agent_name, {
            "masked_data": state["masked_data"],
            "risk_indicators": state["risk_indicators"],
            "crime_types": state["crime_types"],
        }))
    return sends

typology_graph = StateGraph(TypologyState)
typology_graph.add_node("transaction_fraud",   transaction_fraud_agent)
typology_graph.add_node("payment_velocity",    payment_velocity_agent)
typology_graph.add_node("country_risk",        country_risk_agent)
typology_graph.add_node("text_content",        text_content_agent)
typology_graph.add_node("geo_anomaly",         geo_anomaly_agent)
typology_graph.add_node("account_health",      account_health_agent)
typology_graph.add_node("dispute_pattern",     dispute_pattern_agent)
typology_graph.add_node("typology_merge",      merge_typology_results)

# Dynamic parallel dispatch
typology_graph.add_conditional_edges(START, plan_to_typology_dispatch)

# All parallel Agents converge at the merge node
for agent in TYPOLOGY_AGENTS:
    typology_graph.add_edge(agent, "typology_merge")

typology_graph.add_edge("typology_merge", END)
```

### 3.4 Human-in-the-Loop Interrupts

LangGraph natively supports `interrupt_before` / `interrupt_after`, perfectly matching the paper's human-AI collaboration design:

```python
# Set interrupt points at compile time
app = graph.compile(
    checkpointer=checkpointer,
    interrupt_before=["privacy_unmask"],  # Pause before unmasking output, await human review
)

# Streamlit-side execution resume (after receiving human feedback)
# â”€â”€ Narrative Review Page (pages/review.py) â”€â”€
def on_submit_feedback():
    """Investigator modifies the narrative in the Streamlit editor and clicks submit"""
    case_id = st.session_state["current_case_id"]
    feedback = st.session_state["investigator_feedback"]
    config = {"configurable": {"thread_id": case_id}}

    # Update state and resume graph execution
    app.update_state(config, {"human_feedback": feedback})
    with st.spinner("Regenerating narrative based on feedback..."):
        result = app.invoke(None, config)
    st.session_state["sar_result"] = result
    st.rerun()

# UI Components
st.text_area("Investigator Feedback", key="investigator_feedback")
st.button("Submit Feedback & Regenerate", on_click=on_submit_feedback)
```

---

## 4. Streamlit UI Design

### 4.1 UI Architecture Overview

Streamlit serves as the sole interface between investigators and Argus AI, handling all responsibilities: data input, workflow control, narrative review, feedback submission, and result visualization. It uses the **Streamlit Multi-Page App** pattern to organize pages.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit App (app.py)                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Sidebar (Global Navigation)                           â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚  â”‚
â”‚  â”‚  â”‚ ðŸ“„ Case Upload    â”‚ â† JSON file upload / sample      â”‚  â”‚
â”‚  â”‚  â”‚ ðŸ” SAR Generate   â”‚ â† One-click, real-time progress  â”‚  â”‚
â”‚  â”‚  â”‚ âœï¸ Narrative Reviewâ”‚ â† Draft + inline edit + feedback â”‚  â”‚
â”‚  â”‚  â”‚ ðŸ“Š Dashboard      â”‚ â† Crime type/risk/compliance viz â”‚  â”‚
â”‚  â”‚  â”‚ ðŸ“‹ History        â”‚ â† SAR list + search + export     â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â”‚  Settings Panel (Sidebar Bottom)                       â”‚  â”‚
â”‚  â”‚  â€¢ DeepSeek API Key Configuration                      â”‚  â”‚
â”‚  â”‚  â€¢ Compliance Score Threshold Adjustment               â”‚  â”‚
â”‚  â”‚  â€¢ Maximum Iteration Count Setting                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Main Content Area (dynamically rendered per page)     â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â”‚  st.session_state management:                          â”‚  â”‚
â”‚  â”‚  â€¢ current_case: dict     â€” Currently loaded case data â”‚  â”‚
â”‚  â”‚  â€¢ sar_result: dict       â€” LangGraph execution result â”‚  â”‚
â”‚  â”‚  â€¢ graph_status: str      â€” Graph execution status     â”‚  â”‚
â”‚  â”‚  â€¢ thread_id: str         â€” LangGraph thread ID        â”‚  â”‚
â”‚  â”‚  â€¢ iteration_count: int   â€” Current iteration round    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Page Design Details

#### 4.2.1 ðŸ“„ Case Upload Page (`pages/1_Case_Upload.py`)

| Feature | Implementation |
|---|---|
| **JSON File Upload** | `st.file_uploader(type=["json"])` to accept case files uploaded by investigators |
| **Sample Data Selection** | `st.selectbox` to load preset samples from the `data/samples/` directory |
| **Data Preview** | `st.json()` displays raw JSON; `st.dataframe()` shows structured views of transactions, accounts, etc. |
| **Data Validation** | Auto-validates JSON Schema upon upload; uses `st.error()` / `st.success()` for validation feedback |
| **Load to Session** | On successful validation, writes to `st.session_state["current_case"]` and auto-navigates to the generation page |

#### 4.2.2 ðŸ” SAR Generation Page (`pages/2_SAR_Generate.py`)

| Feature | Implementation |
|---|---|
| **One-Click Generate** | `st.button("ðŸš€ Start SAR Generation")` triggers LangGraph graph execution |
| **Real-Time Progress** | Uses `st.status()` + `st.write_stream()` to stream each Agent's execution status |
| **Agent Progress Tracking** | Custom `progress_tracker` component displaying a step bar: Data Ingestion âœ… â†’ Privacy Masking âœ… â†’ Crime Detection ðŸ”„ â†’ ... |
| **Intermediate Result Preview** | Collapsible `st.expander()` showing each Agent's output summary |
| **Error Handling** | Catches exceptions with `st.error()` display and retry support |

```python
# Core execution logic (pages/2_SAR_Generate.py)
if st.button("ðŸš€ Start SAR Generation"):
    case_data = st.session_state["current_case"]
    thread_id = case_data["case_id"]
    config = {"configurable": {"thread_id": thread_id}}

    with st.status("Generating SAR narrative...", expanded=True) as status:
        # stream_mode="updates" retrieves results node by node
        for event in app.stream(
            {"raw_data": case_data, "case_id": thread_id},
            config=config,
            stream_mode="updates",
        ):
            for node_name, node_output in event.items():
                st.write(f"âœ… **{node_name}** completed")
                with st.expander(f"{node_name} details", expanded=False):
                    st.json(node_output)

        status.update(label="SAR generation complete!", state="complete")

    # Save results to session
    st.session_state["sar_result"] = app.get_state(config).values
    st.session_state["thread_id"] = thread_id
```

#### 4.2.3 âœï¸ Narrative Review Page (`pages/3_Narrative_Review.py`)

This is the **core page for Human-in-the-Loop**. The paper emphasizes that investigators must be able to review and modify AI-generated drafts:

| Feature | Implementation |
|---|---|
| **Narrative Display** | `st.markdown()` renders the formatted SAR narrative (Intro + Body + Conclusion) |
| **Inline Editing** | `st.text_area()` provides an editable text area for the narrative draft |
| **CoT Reasoning Chain** | `st.expander("ðŸ§  Reasoning Process")` displays Chain-of-Thought for explainability |
| **Compliance Score** | `st.metric()` + `st.progress()` shows compliance validation score and pass/fail status |
| **Compliance Details** | `st.expander()` displays compliance check results across all dimensions |
| **Feedback Submission** | `st.text_area()` + `st.button()` to submit revision comments, triggering iterative regeneration |
| **Approve/Reject** | `st.button("âœ… Approve")` / `st.button("âŒ Reject")` for final decision |
| **Iteration Counter** | `st.info()` displays current iteration round / maximum rounds |

#### 4.2.4 ðŸ“Š Analysis Dashboard (`pages/4_Analysis_Dashboard.py`)

| Feature | Implementation |
|---|---|
| **Crime Type Confidence** | `plotly` horizontal bar chart showing detection confidence for each crime type |
| **Transaction Timeline** | `plotly` timeline scatter plot annotating suspicious transaction nodes |
| **Risk Indicator Heatmap** | `plotly` heatmap displaying risk ratings across dimensions |
| **Related Entity Network** | `plotly` / `st.graphviz_chart` showing subject-account-entity relationship graph |
| **Typology Agent Results** | `st.columns()` multi-column layout, each column showing a Typology Agent's analysis summary |

#### 4.2.5 ðŸ“‹ History Page (`pages/5_History.py`)

| Feature | Implementation |
|---|---|
| **SAR List** | `st.dataframe()` displays historically generated SARs (ID, date, status, crime types, score) |
| **Search & Filter** | `st.text_input()` + `st.multiselect()` to filter by keywords, crime types, status |
| **Detail View** | Click a row to navigate to the complete SAR detail view |
| **JSON Export** | `st.download_button()` exports SAR results as JSON files |

### 4.3 Session State Management

Streamlit's `st.session_state` serves as the UI layer's state hub, bridging user interactions and LangGraph execution:

```python
# ui/session.py â€” Session State initialization and management

def init_session_state():
    """Called in app.py to initialize all session variables"""
    defaults = {
        "current_case": None,           # Current case JSON data
        "sar_result": None,             # LangGraph execution result
        "thread_id": None,              # LangGraph checkpoint thread_id
        "graph_status": "idle",         # idle / running / interrupted / completed
        "iteration_count": 0,           # Feedback iteration counter
        "history": [],                  # Historical SAR records list
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

def reset_case():
    """Reset current case-related state"""
    st.session_state["current_case"] = None
    st.session_state["sar_result"] = None
    st.session_state["thread_id"] = None
    st.session_state["graph_status"] = "idle"
    st.session_state["iteration_count"] = 0
```

### 4.4 Launch Method

```bash
# Launch the Streamlit application
streamlit run src/app.py

# app.py entry file structure
# â”€â”€ src/app.py â”€â”€
import streamlit as st
from ui.session import init_session_state

st.set_page_config(
    page_title="Argus AI",
    page_icon="ðŸ”",
    layout="wide",
    initial_sidebar_state="expanded",
)

init_session_state()

st.title("ðŸ” Argus AI")
st.markdown("**AML Compliance Narrative Intelligence Platform** â€” Multi-Agent Collaborative SAR Auto-Generation System")

# Home page: System overview / Quick access
col1, col2, col3 = st.columns(3)
with col1:
    st.metric("SARs Pending Review", "3")
with col2:
    st.metric("Generated Today", "12")
with col3:
    st.metric("Avg Compliance Score", "0.87")
```

---

## 5. Agent Design Details

### 5.1 Unified Agent Pattern

Each Agent is represented as a **node function** in LangGraph, following a unified pattern:

```python
def agent_function(state: SARState) -> dict:
    """
    1. Read required inputs from state
    2. Execute the Agent's core logic (LLM call / ML inference / tool invocation)
    3. Return state fields to update (dict)
    """
    # ... core logic
    return {"field_to_update": new_value}
```

### 5.2 Agent Responsibilities and Implementation Strategies

#### 5.2.1 Data Ingestion Agent (`ingest`)

| Item | Description |
|---|---|
| **Input** | `raw_data` (JSON) |
| **Output** | `structured_data` |
| **Implementation** | Pure Python data transformation, no LLM dependency. Parses transaction records, account metadata, KYC information, and risk signals from JSON, outputting a standardized structure |

#### 5.2.2 AI-Privacy Guard Agent (`privacy_mask` / `privacy_unmask`)

| Item | Description |
|---|---|
| **Input** | `structured_data` |
| **Output** | `masked_data`, `mask_mapping` |
| **Implementation** | MVP stage uses Microsoft Presidio / spaCy NER to identify PII (names, SSN, addresses, account numbers, etc.) and generates an anonymization mapping table. To be later replaced with a self-trained RoBERTa+CRF model |
| **Bidirectional Operation** | `privacy_mask` masks sensitive info â†’ LLM processes â†’ `privacy_unmask` restores original data |

#### 5.2.3 Crime Type Detection Agent (`crime_detect`)

| Item | Description |
|---|---|
| **Input** | `masked_data` |
| **Output** | `risk_indicators`, `crime_types` |
| **Implementation** | Dual-component: â‘  Rule engine extracts risk indicators (abnormal transaction patterns, high-risk countries, unusual frequencies, etc.) â‘¡ scikit-learn ensemble models (RF / GBM) output crime type probability rankings |
| **LLM Assistance** | Optional: For emerging types not covered by rules, invoke DeepSeek for auxiliary classification |

#### 5.2.4 Planning Agent (`plan`)

| Item | Description |
|---|---|
| **Input** | `crime_types`, `risk_indicators`, `masked_data` |
| **Output** | `execution_plan`, `active_typology_agents` |
| **Implementation** | Invokes DeepSeek to decide, based on detected crime types and confidence levels: â‘  Which Typology Agents to activate â‘¡ Whether external intelligence is needed â‘¢ Narrative focus and structural planning |

#### 5.2.5 Specialized Typology Detection Agents (7 Agents)

| Agent | Core Logic |
|---|---|
| **transaction_fraud** | Analyzes transaction amount/frequency/counterparty patterns; detects structuring, layering, and anomalous large transactions |
| **payment_velocity** | Computes transaction frequency/volume within time windows; detects sudden high-frequency activity |
| **country_risk** | Cross-references countries/regions involved in transactions against sanctions lists / FATF high-risk lists |
| **text_content** | NLP analysis of customer communications and transaction notes; detects suspicious keywords/semantic patterns |
| **geo_anomaly** | Detects geographic inconsistencies (login location vs. transaction location vs. registration location) |
| **account_health** | Evaluates account historical behavior baselines; detects anomalous deviations |
| **dispute_pattern** | Analyzes dispute/chargeback patterns; detects fraudulent disputes |

Each Agent uses a mix of **rule engines + ML models + DeepSeek reasoning**, outputting structured risk assessment reports.

#### 5.2.6 External Intelligence Agent (`external_intel`)

| Item | Description |
|---|---|
| **Input** | `crime_types`, `masked_data`, `execution_plan` |
| **Output** | `external_intel` |
| **Implementation** | Connects to external MCP Servers via MCP Client SDK, dynamically discovering and invoking data sources (adverse media, sanctions lists, regulatory bulletins). MVP stage simulates MCP calls with local JSON data |

#### 5.2.7 Narrative Generation Agent (`narrative_generate`)

| Item | Description |
|---|---|
| **Input** | `masked_data`, `typology_results`, `external_intel`, `execution_plan`, `human_feedback` (if any) |
| **Output** | `narrative_draft`, `narrative_intro`, `chain_of_thought` |
| **Implementation** | Invokes DeepSeek using Chain-of-Thought prompting to generate a FinCEN-compliant SAR narrative draft. Prompt templates include: narrative structure guidelines (5W1H), crime type context, regulatory requirements, and historical narrative references |

#### 5.2.8 Compliance Validation Agent (`compliance_validate`) â€” Agent-as-a-Judge

| Item | Description |
|---|---|
| **Input** | `narrative_draft`, `typology_results`, `masked_data` |
| **Output** | `compliance_result`, `compliance_score` |
| **Implementation** | Dual validation: â‘  **Rule-based validation** â€” Checks whether all required elements are present (subject info, date range, transaction amounts, crime types) â‘¡ **Semantic validation** â€” Invokes DeepSeek to evaluate narrative coherence, logical completeness, and regulatory compliance, producing structured scores |
| **Routing Logic** | score â‰¥ threshold â†’ PASS â†’ proceed to unmasking output; score < threshold â†’ FAIL â†’ generate improvement suggestions â†’ Feedback Agent |

#### 5.2.9 Feedback Agent (`feedback_refine`)

| Item | Description |
|---|---|
| **Input** | `compliance_result`, `narrative_draft`, `human_feedback` |
| **Output** | Revision instructions for updating `narrative_draft`, `iteration_count` +1 |
| **Implementation** | Synthesizes compliance validation failure reasons + human feedback to generate specific narrative revision instructions, passed to the next round of narrative generation |

---

## 6. Dynamic Memory System

### 6.1 Three-Layer Memory Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MemoryManager                   â”‚
â”‚  (Unified interface; Agents are unaware of   â”‚
â”‚   underlying storage differences)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Regulatory  â”‚ Historical   â”‚ Typology       â”‚
â”‚ Memory      â”‚ Narrative    â”‚ Specific       â”‚
â”‚             â”‚ Memory       â”‚ Memory         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ChromaDB    â”‚ ChromaDB     â”‚ SQLite         â”‚
â”‚ (Vector)    â”‚ (Vector)     â”‚ (Structured)   â”‚
â”‚             â”‚              â”‚                â”‚
â”‚ â€¢ AML Regs  â”‚ â€¢ Hist. SARs â”‚ â€¢ Risk Indicatorâ”‚
â”‚ â€¢ FinCEN    â”‚ â€¢ Approval   â”‚   Patterns     â”‚
â”‚   Guidelinesâ”‚   Records    â”‚ â€¢ Crime Type   â”‚
â”‚ â€¢ FATF      â”‚ â€¢ Narrative  â”‚   Features     â”‚
â”‚   Recs      â”‚   Templates  â”‚ â€¢ Detection    â”‚
â”‚             â”‚              â”‚   Thresholds   â”‚
â”‚             â”‚              â”‚ â€¢ Hist. Resultsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Integration with LangGraph

The memory system is integrated as **Tools for LangGraph nodes**, with Agents accessing it through standard tool calls:

```python
@tool
def search_regulatory_memory(query: str) -> list[Document]:
    """Search the regulatory memory store"""

@tool
def search_historical_narratives(query: str, crime_type: str) -> list[Document]:
    """Search historical SAR narratives"""

@tool
def get_typology_patterns(crime_type: str) -> dict:
    """Retrieve historical analysis patterns for a specific crime type"""
```

---

## 7. LLM Gateway Design

### 7.1 DeepSeek-First Multi-Model Strategy

```python
class LLMGateway:
    """Unified LLM invocation entry point, supporting per-Agent-role routing to different models"""

    MODEL_ROUTING = {
        # Agent Role           â†’ Model Configuration
        "planning":          {"provider": "deepseek", "model": "deepseek-chat"},
        "narrative":         {"provider": "deepseek", "model": "deepseek-chat"},
        "compliance_judge":  {"provider": "deepseek", "model": "deepseek-chat"},
        "crime_detection":   {"provider": "deepseek", "model": "deepseek-chat"},
        "typology":          {"provider": "deepseek", "model": "deepseek-chat"},
        "evaluation":        {"provider": "deepseek", "model": "deepseek-chat"},
    }
```

### 7.2 DeepSeek Integration

Connects to the DeepSeek API via LangChain's `ChatOpenAI` compatible interface:

```python
from langchain_openai import ChatOpenAI

deepseek_llm = ChatOpenAI(
    model="deepseek-chat",
    base_url="https://api.deepseek.com",
    api_key=settings.DEEPSEEK_API_KEY,
    temperature=0.1,        # Low randomness for SAR generation
    max_tokens=8192,
)
```

---

## 8. Data Models and Sample Data

### 8.1 Input Data Format (JSON)

```json
{
  "case_id": "CASE-2026-00142",
  "alert_date": "2026-01-15",
  "priority": "high",
  "subject": {
    "name": "John Michael Smith",
    "dob": "1985-03-22",
    "ssn": "123-45-6789",
    "address": "456 Oak Avenue, Miami, FL 33101",
    "phone": "+1-305-555-0142",
    "email": "jmsmith85@email.com",
    "occupation": "Self-employed consultant",
    "risk_rating": "high",
    "customer_since": "2023-06-10"
  },
  "accounts": [
    {
      "account_id": "ACC-9821034",
      "account_type": "checking",
      "opened_date": "2023-06-10",
      "balance": 45230.00,
      "currency": "USD",
      "branch": "Miami Downtown"
    },
    {
      "account_id": "ACC-9821035",
      "account_type": "savings",
      "opened_date": "2023-07-01",
      "balance": 128500.00,
      "currency": "USD",
      "branch": "Miami Downtown"
    }
  ],
  "transactions": [
    {
      "txn_id": "TXN-20260110-001",
      "date": "2026-01-10",
      "type": "wire_transfer_in",
      "amount": 9800.00,
      "currency": "USD",
      "from_account": "EXT-OFFSHORE-8831",
      "to_account": "ACC-9821034",
      "from_entity": "Global Trade Solutions Ltd",
      "from_country": "BZ",
      "description": "Consulting payment",
      "risk_flags": ["structured_amount", "high_risk_jurisdiction"]
    },
    {
      "txn_id": "TXN-20260111-002",
      "date": "2026-01-11",
      "type": "wire_transfer_in",
      "amount": 9700.00,
      "currency": "USD",
      "from_account": "EXT-OFFSHORE-8831",
      "to_account": "ACC-9821034",
      "from_entity": "Global Trade Solutions Ltd",
      "from_country": "BZ",
      "description": "Consulting payment Q4",
      "risk_flags": ["structured_amount", "high_risk_jurisdiction", "rapid_succession"]
    },
    {
      "txn_id": "TXN-20260112-003",
      "date": "2026-01-12",
      "type": "internal_transfer",
      "amount": 19000.00,
      "currency": "USD",
      "from_account": "ACC-9821034",
      "to_account": "ACC-9821035",
      "description": "Savings allocation",
      "risk_flags": ["layering_pattern"]
    },
    {
      "txn_id": "TXN-20260113-004",
      "date": "2026-01-13",
      "type": "wire_transfer_out",
      "amount": 15000.00,
      "currency": "USD",
      "from_account": "ACC-9821035",
      "to_account": "EXT-SHELL-7742",
      "to_entity": "Sunrise Holdings LLC",
      "to_country": "PA",
      "description": "Investment deposit",
      "risk_flags": ["shell_company_indicator", "high_risk_jurisdiction"]
    },
    {
      "txn_id": "TXN-20260113-005",
      "date": "2026-01-13",
      "type": "cash_withdrawal",
      "amount": 4500.00,
      "currency": "USD",
      "from_account": "ACC-9821034",
      "location": "ATM - Hialeah, FL",
      "risk_flags": ["geographic_anomaly"]
    }
  ],
  "kyc": {
    "verification_status": "verified",
    "last_review_date": "2025-06-10",
    "source_of_funds": "Consulting income",
    "expected_activity": "low_volume_domestic",
    "actual_activity_profile": "high_volume_international",
    "pep_status": false,
    "adverse_media_hits": [
      {
        "date": "2025-11-20",
        "source": "Financial Times",
        "summary": "Subject's former business partner indicted for wire fraud scheme"
      }
    ]
  },
  "communications": [
    {
      "date": "2026-01-09",
      "channel": "secure_message",
      "direction": "inbound",
      "content": "Need to move funds quickly before end of quarter. Can you expedite the international transfers?",
      "flagged": true,
      "flag_reason": "urgency_pressure"
    },
    {
      "date": "2026-01-14",
      "channel": "phone_note",
      "direction": "outbound",
      "content": "Customer called to inquire about increasing wire transfer limits. Became evasive when asked about purpose of recent transfers.",
      "flagged": true,
      "flag_reason": "evasive_behavior"
    }
  ],
  "alerts": [
    {
      "alert_id": "ALT-20260115-001",
      "type": "structuring",
      "severity": "high",
      "description": "Multiple incoming wire transfers just below $10,000 threshold within 48-hour window",
      "triggered_date": "2026-01-15"
    },
    {
      "alert_id": "ALT-20260115-002",
      "type": "high_risk_jurisdiction",
      "severity": "medium",
      "description": "Wire transfers originating from Belize and destined to Panama â€” both FATF-monitored jurisdictions",
      "triggered_date": "2026-01-15"
    }
  ],
  "related_entities": [
    {
      "entity_name": "Global Trade Solutions Ltd",
      "entity_type": "company",
      "jurisdiction": "Belize",
      "relationship": "funds_originator",
      "risk_notes": "Shell company characteristics â€” no verifiable business operations"
    },
    {
      "entity_name": "Sunrise Holdings LLC",
      "entity_type": "company",
      "jurisdiction": "Panama",
      "relationship": "funds_recipient",
      "risk_notes": "Registered 2025-09 â€” minimal operating history"
    }
  ]
}
```

### 8.2 SAR Output Format (JSON)

```json
{
  "sar_id": "SAR-2026-00142",
  "case_id": "CASE-2026-00142",
  "generated_at": "2026-01-16T10:30:00Z",
  "status": "review",
  "crime_types_detected": [
    {"type": "structuring", "confidence": 0.92},
    {"type": "money_laundering_layering", "confidence": 0.87},
    {"type": "shell_company_activity", "confidence": 0.78}
  ],
  "narrative": {
    "intro": "This SAR is being filed to report suspicious activity...",
    "body": "Between January 10, 2026, and January 13, 2026, the subject...",
    "conclusion": "Based on the above analysis, the described transaction patterns..."
  },
  "compliance_validation": {
    "score": 0.85,
    "status": "PASS",
    "checks": { ... }
  },
  "chain_of_thought": [ ... ],
  "metadata": {
    "iteration_count": 2,
    "agents_activated": [ ... ],
    "processing_time_seconds": 45
  }
}
```

---

## 9. Project Directory Structure

```
Argus-v2/
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ARCHITECTURE.md              # This document
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py                       # Streamlit application entry (home page)
â”‚   â”œâ”€â”€ config.py                    # Pydantic Settings configuration
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                        # Core abstractions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py                 # SARState TypedDict definition
â”‚   â”‚   â”œâ”€â”€ models.py                # Common data models (Pydantic)
â”‚   â”‚   â””â”€â”€ llm_gateway.py           # Unified LLM Gateway (DeepSeek-first)
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/                       # LangGraph graph definitions
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ sar_graph.py             # Main graph: SARGenerationGraph
â”‚   â”‚   â”œâ”€â”€ typology_subgraph.py     # Subgraph: TypologySubgraph
â”‚   â”‚   â””â”€â”€ routing.py               # Conditional routing functions
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/                      # Agent implementations (LangGraph nodes)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ingestion.py             # Data Ingestion Agent
â”‚   â”‚   â”œâ”€â”€ privacy_guard.py         # AI-Privacy Guard (mask/unmask)
â”‚   â”‚   â”œâ”€â”€ crime_detection.py       # Crime Type Detection Agent
â”‚   â”‚   â”œâ”€â”€ planning.py              # Planning Agent (orchestrator)
â”‚   â”‚   â”œâ”€â”€ narrative.py             # Narrative Generation Agent
â”‚   â”‚   â”œâ”€â”€ compliance.py            # Compliance Validation Agent (Agent-as-a-Judge)
â”‚   â”‚   â”œâ”€â”€ feedback.py              # Feedback Agent
â”‚   â”‚   â”œâ”€â”€ external_intel.py        # External Intelligence Agent (MCP)
â”‚   â”‚   â””â”€â”€ typology/                # 7 Specialized Typology Detection Agents
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ transaction_fraud.py
â”‚   â”‚       â”œâ”€â”€ payment_velocity.py
â”‚   â”‚       â”œâ”€â”€ country_risk.py
â”‚   â”‚       â”œâ”€â”€ text_content.py
â”‚   â”‚       â”œâ”€â”€ geo_anomaly.py
â”‚   â”‚       â”œâ”€â”€ account_health.py
â”‚   â”‚       â””â”€â”€ dispute_pattern.py
â”‚   â”‚
â”‚   â”œâ”€â”€ infrastructure/              # Infrastructure
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ memory/                  # Three-layer dynamic memory
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.py           # MemoryManager unified interface
â”‚   â”‚   â”‚   â”œâ”€â”€ regulatory.py        # Regulatory memory (ChromaDB)
â”‚   â”‚   â”‚   â”œâ”€â”€ historical.py        # Historical narrative memory (ChromaDB)
â”‚   â”‚   â”‚   â””â”€â”€ typology.py          # Typology-specific memory (SQLite)
â”‚   â”‚   â”œâ”€â”€ tools/                   # Analytical tools
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ risk_indicators.py   # Risk indicator extraction
â”‚   â”‚   â”‚   â”œâ”€â”€ account_linking.py   # Account linking analysis
â”‚   â”‚   â”‚   â””â”€â”€ external_search.py   # External intelligence search
â”‚   â”‚   â””â”€â”€ mcp_client.py            # MCP client
â”‚   â”‚
â”‚   â””â”€â”€ ui/                          # Streamlit UI layer
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ pages/                   # Streamlit multi-page
â”‚       â”‚   â”œâ”€â”€ 1_Case_Upload.py     # Case data upload and preview
â”‚       â”‚   â”œâ”€â”€ 2_SAR_Generate.py    # SAR generation workflow and real-time progress
â”‚       â”‚   â”œâ”€â”€ 3_Narrative_Review.py# Narrative draft review and feedback
â”‚       â”‚   â”œâ”€â”€ 4_Analysis_Dashboard.py # Risk analysis visualization
â”‚       â”‚   â””â”€â”€ 5_History.py         # Historical SAR management
â”‚       â”œâ”€â”€ components/              # Reusable UI components
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ case_viewer.py       # Case data display component
â”‚       â”‚   â”œâ”€â”€ narrative_editor.py  # Narrative editor component
â”‚       â”‚   â”œâ”€â”€ progress_tracker.py  # Agent execution progress component
â”‚       â”‚   â””â”€â”€ risk_charts.py       # Risk chart component
â”‚       â””â”€â”€ session.py               # Session State management
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ samples/                     # Sample data
â”‚       â”œâ”€â”€ case_structuring.json    # Sample: Structuring transactions
â”‚       â”œâ”€â”€ case_elder_exploit.json  # Sample: Elder financial exploitation
â”‚       â””â”€â”€ case_shell_company.json  # Sample: Shell company money laundering
â”‚
â”œâ”€â”€ prompts/                         # Prompt templates
â”‚   â”œâ”€â”€ planning.yaml
â”‚   â”œâ”€â”€ narrative_generation.yaml
â”‚   â”œâ”€â”€ compliance_validation.yaml
â”‚   â””â”€â”€ crime_detection.yaml
â”‚
â”œâ”€â”€ evaluation/                      # Evaluation framework
â”‚   â”œâ”€â”€ golden_datasets/             # Golden datasets
â”‚   â”œâ”€â”€ scoring.py                   # Scoring logic
â”‚   â””â”€â”€ runner.py                    # Evaluation runner
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚
â”œâ”€â”€ pyproject.toml                   # Project dependencies and metadata
â””â”€â”€ README.md
```

---

## 10. Key Dependencies

```toml
[project]
name = "Argus-v2"
requires-python = ">=3.11"

dependencies = [
    # â”€â”€ LangGraph / LangChain â”€â”€
    "langgraph>=0.2.0",
    "langchain>=0.3.0",
    "langchain-openai>=0.2.0",       # DeepSeek via OpenAI-compatible interface
    "langchain-community>=0.3.0",

    # â”€â”€ UI â”€â”€
    "streamlit>=1.40.0",
    "plotly>=5.24.0",              # Analysis dashboard charts

    # â”€â”€ Data / ML â”€â”€
    "pydantic>=2.0",
    "pydantic-settings>=2.0",
    "scikit-learn>=1.5.0",

    # â”€â”€ Memory / Vector â”€â”€
    "chromadb>=0.5.0",

    # â”€â”€ Privacy (MVP) â”€â”€
    "presidio-analyzer>=2.2",
    "presidio-anonymizer>=2.2",
    "spacy>=3.7",

    # â”€â”€ MCP â”€â”€
    "mcp>=1.0",

    # â”€â”€ Utilities â”€â”€
    "httpx>=0.27",
    "pyyaml>=6.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0",
    "pytest-asyncio>=0.24",
    "ruff>=0.6",
]
```

---

## 11. Implementation Roadmap

| Phase | Objective | Modules Involved | Expected Output |
|---|---|---|---|
| **Phase 0** | Project Skeleton | Project structure, configuration, State definition, LLM Gateway | Runnable empty shell project |
| **Phase 1** | Minimal Pipeline | Data Ingestion â†’ Crime Type Detection (simplified) â†’ Narrative Generation â†’ Output. Three-node LangGraph linear graph | End-to-end runnable, generating initial SAR draft |
| **Phase 2** | Full Agent Suite | Planning Agent, 7 Typology Agents (subgraph), Compliance Validation Agent, Feedback Loop | Complete LangGraph main graph + subgraph |
| **Phase 3** | Security & Memory | AI-Privacy Guard, Three-layer Dynamic Memory, External Intelligence Agent (MCP) | Privacy compliance + context augmentation |
| **Phase 4** | Human-AI Collaboration | Human-in-the-Loop interrupts, Streamlit review pages, feedback interaction components | Interactive review workflow |
| **Phase 5** | Evaluation & Optimization | Offline evaluation framework, Agent-as-a-Judge online validation, prompt optimization | Quantifiable quality assurance |
